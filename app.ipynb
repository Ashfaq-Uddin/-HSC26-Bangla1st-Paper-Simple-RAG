{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abefdc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import gradio as gr\n",
    "\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain_core.documents import Document\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147ccde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"gpt-4o-mini\"\n",
    "db_name = \"vector_db\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be110d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY', 'your-key-if-not-using-env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34d6b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_path = \"D:/Udemy - LLM Engineering Master AI, Large Language Models & Agents 2024-12/llm_engineering/week5/HSC26_Bangla1st_OCR_With_Tables.txt\"  # Change to your actual txt filename\n",
    "loader = TextLoader(txt_path, encoding=\"utf-8\")\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22ee105",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_bengali_text(text):\n",
    "    return ' '.join(text.replace('\\u200c', '').replace('\\u200b', '').replace('\\n', ' ').split())\n",
    "\n",
    "cleaned_documents = [\n",
    "    Document(page_content=clean_bengali_text(doc.text), metadata=getattr(doc, \"metadata\", {}))\n",
    "    for doc in documents\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e045b552",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
    "chunks = text_splitter.create_documents([doc.text for doc in documents])\n",
    "\n",
    "# text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
    "# chunks = text_splitter.create_documents([doc.text for doc in documents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3851392",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba28d416",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"BAAI/bge-m3\",\n",
    "    encode_kwargs={\"normalize_embeddings\": True}\n",
    ")\n",
    "\n",
    "# embeddings = HuggingFaceEmbeddings(\n",
    "#     model_name=\"l3cube-pune/bengali-sentence-similarity-sbert\",\n",
    "#     encode_kwargs={\"normalize_embeddings\": True}\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a202ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(db_name):\n",
    "    Chroma(persist_directory=db_name, embedding_function=embeddings).delete_collection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779821e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = Chroma.from_documents(documents=chunks, embedding=embeddings, persist_directory=db_name)\n",
    "print(f\"Vectorstore created with {vectorstore._collection.count()} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e182aea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_answer(query, history):\n",
    "    \n",
    "    docs = vectorstore.similarity_search(query, k=10)\n",
    "\n",
    "    print(\"üîç Retrieved Chunks:\")\n",
    "    for i, doc in enumerate(docs):\n",
    "        print(f\"\\n--- Chunk {i+1} ---\\n{doc.page_content}\")\n",
    "\n",
    "    context = \"\\n\".join([doc.page_content for doc in docs])\n",
    "    \n",
    "    short_term = \"\\n\".join([f\"Q: {q}\\nA: {a}\" for q, a in history[-3:]])\n",
    "    prompt = f\"\"\"You are a multilingual assistant capable of understanding and answering both Bengali and English queries. Your main purpose is to answer factual questions by retrieving information from a Bengali literature knowledge base, specifically the book \"HSC26 Bangla 1st Paper\". You must ground your answers in the retrieved content. However, you should also respond naturally to general conversation or small talk, even if it doesn't require retrieval. \n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Recent Q&A:\n",
    "{short_term}\n",
    "\n",
    "User Question: {query}\n",
    "Answer:\"\"\"\n",
    "    llm = ChatOpenAI(model=MODEL, temperature=0)\n",
    "    response = llm.invoke(prompt)\n",
    "    return response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca179930",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_interface(query, history=[]):\n",
    "    answer = rag_answer(query, history)\n",
    "    history = history + [(query, answer)]\n",
    "    return history, history\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"# üìö Multilingual RAG: Bangla & English\")\n",
    "    chatbot = gr.Chatbot()\n",
    "    state = gr.State([])\n",
    "    with gr.Row():\n",
    "        txt = gr.Textbox(label=\"Ask a question (English or Bangla)\")\n",
    "        submit = gr.Button(\"Submit\")\n",
    "    submit.click(chat_interface, [txt, state], [chatbot, state])\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65827e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
